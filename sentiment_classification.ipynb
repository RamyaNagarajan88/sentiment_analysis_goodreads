{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#implemented ideas from https://towardsdatascience.com/yet-another-twitter-sentiment-analysis-part-1-tackling-class-imbalance-4d7a7f717d44"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import json\r\n",
    "import re\r\n",
    "import string\r\n",
    "import nltk\r\n",
    "import spacy\r\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "nltk.download('words')\r\n",
    "eng_words=set(nltk.corpus.words.words())\r\n",
    "nltk.download('stopwords')\r\n",
    "from nltk.corpus import stopwords\r\n",
    "stopwords=stopwords.words('english')\r\n",
    "stopwords.extend(['book','story','read','reading','really','one'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package words to /home/ramya/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ramya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "filepath='E:/Ramya/brushUps/Basics/ML using sklearn/Projects/Sentiment_analysis/data/goodreads_reviews_children.json.gz'\r\n",
    "with open(filepath) as f:\r\n",
    "    lines=f.read().splitlines()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_inter=pd.DataFrame(lines)\r\n",
    "data_inter.columns=['json_element']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data_inter['json_element'].apply(json.loads)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0         {'user_id': '8842281e1d1347389f2ab93d60773d4d'...\n",
       "1         {'user_id': '8842281e1d1347389f2ab93d60773d4d'...\n",
       "2         {'user_id': '8842281e1d1347389f2ab93d60773d4d'...\n",
       "3         {'user_id': '8842281e1d1347389f2ab93d60773d4d'...\n",
       "4         {'user_id': '8842281e1d1347389f2ab93d60773d4d'...\n",
       "                                ...                        \n",
       "734635    {'user_id': '480ac8b4df39533a6c7fe6ae109aa56a'...\n",
       "734636    {'user_id': 'afcd096765a8c354be0706ab1324999b'...\n",
       "734637    {'user_id': 'd94c83867337514c94738b57a1d19677'...\n",
       "734638    {'user_id': '48a10d546ba07520ce194dc18e687be4'...\n",
       "734639    {'user_id': 'da6f9516279ed671027308abd21318bd'...\n",
       "Name: json_element, Length: 734640, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data=pd.json_normalize(data_inter['json_element'].apply(json.loads))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "reviews_data=data[['book_id','rating','review_text']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                       \"here's\": \"here is\",\n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" } "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def reviewsTextCleaning(review):\n",
    "    #expanding words\n",
    "    review=' '.join([contraction_mapping[word] if word in contraction_mapping.keys() else word for word in review.split()])\n",
    "    #removing @mentions\n",
    "    review=re.sub(r'@[A-Za-z0-9]+',' ',review)\n",
    "    review=review.lower()\n",
    "    review=review.strip()\n",
    "    review=review.replace('\\n','')\n",
    "    review=review.replace('\\t','')\n",
    "    #converting apostrophes to single quote\n",
    "    review=review.replace(\"â€™\", \"'\")\n",
    "    #removing punctuations\n",
    "    review=review.translate(str.maketrans('','',string.punctuation))\n",
    "    #removinf digits\n",
    "    review=re.sub(r'\\d+','',review)\n",
    "    #removing urls\n",
    "    review=re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',review)\n",
    "    #removing tags\n",
    "    remove_tags=re.compile('<.*?>')\n",
    "    review=re.sub(remove_tags,'',review) \n",
    "    #lemmatization\n",
    "    nlp=spacy.load('en_core_web_sm',disable=['parser','ner'])\n",
    "    review=' '.join([token.lemma_ for token in nlp(review)])\n",
    "    #ignoring gibberish words\n",
    "    review=' '.join(w for w in nltk.wordpunct_tokenize(review) if w.lower() in eng_words or not w.isalpha())\n",
    "\n",
    "    return review                                                                                                                                                                                                                                                                                                                                                   "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}